{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import itertools\n",
    "import pathlib\n",
    "from typing import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from matplotlib import rc\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "font = {'family': 'Times New Roman', 'weight': 'bold', 'size': 12}\n",
    "rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "value = 5.1\n",
    "\n",
    "ba = bytearray(struct.pack(\"f\", value)) \n",
    "ba "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cmds = 10\n",
    "n_files = 3\n",
    "local_ranks = [0, 1]\n",
    "local_ranks_iter = itertools.cycle(local_ranks)\n",
    "cmds = []\n",
    "\n",
    "for i in range(1, n_cmds + 1):\n",
    "    local_rank = next(local_ranks_iter)\n",
    "    cmd = f'cmd --id {i} --local_rank {local_rank} MODEL.DEVICE \\\"CUDA:{local_rank}\\\"'\n",
    "    cmds.append(cmd)\n",
    "\n",
    "def get_cmd_cuda_device(cmd):\n",
    "    cuda_str = \"CUDA:\"\n",
    "    pos = cmd.find(cuda_str)\n",
    "    \n",
    "    if pos < 0:\n",
    "        device_id = 0\n",
    "    else:\n",
    "        id_pos = pos + len(cuda_str)\n",
    "        device_id = int(cmd[id_pos:id_pos + 1])\n",
    "    \n",
    "    return device_id\n",
    "\n",
    "cmds_sorted = sorted(cmds, key=get_cmd_cuda_device)\n",
    "for cuda_device, cmd_cuda_group in itertools.groupby(cmds_sorted, key=get_cmd_cuda_device):\n",
    "    print(f\"Device: {cuda_device}\")\n",
    "    for cmd in cmd_cuda_group:\n",
    "        print(f\"\\t{cmd}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil, floor\n",
    "\n",
    "n_files = 6\n",
    "n_files_portion_pool = float(n_files)\n",
    "group_sizes = [12, 4]\n",
    "for group_size in group_sizes:\n",
    "    n_curr_files_portion = (group_size / sum(group_sizes)) * n_files\n",
    "    n_curr_files = int(round(n_curr_files_portion))\n",
    "    print(n_curr_files, n_curr_files_portion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_split(cmds, 3)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f91a5d6e4747d83f2ca8abaaaf7aacd52eac54e528eee770e3eb228d51a3694d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
