{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from maskrcnn_benchmark.structures.bounding_box import BoxList\n",
    "from maskrcnn_benchmark.structures.boxlist_ops import boxlist_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 128, 15, 15]), torch.Size([100, 128]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_rois = 100\n",
    "n_channels = 128\n",
    "output_size = 15\n",
    "\n",
    "def features_to_emb(features: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Computes embedding vectors from tracker template (exemplar) features.\n",
    "    For each feature tensor in a batch, it applies global average pooling along\n",
    "    the channel dimension. Afterwards, it L2-normalizes the vectors to project\n",
    "    them onto a hypersphere.\n",
    "\n",
    "    Args:\n",
    "        features (torch.Tensor): template features of shape [B, C, S, S]\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: embedding vectors of shape [B, C]\n",
    "    \"\"\"\n",
    "    assert features.ndim == 4\n",
    "    assert features.shape[-1] == features.shape[-2]\n",
    "    \n",
    "    size = features.shape[-1]\n",
    "    avg = F.avg_pool2d(features, kernel_size=size)   # [B, C, 1, 1]\n",
    "    avg  = avg.squeeze()  # [B, C]\n",
    "    norm = torch.linalg.norm(avg, dim=1)  # [B,]\n",
    "    emb = avg / norm[..., None]  # [B, C]\n",
    "    \n",
    "    return emb\n",
    "\n",
    "features = torch.rand((n_rois, n_channels, output_size, output_size))\n",
    "emb = features_to_emb(features)\n",
    "features.shape, emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedMarginContrastiveLoss(nn.Module):\n",
    "    _ZERO = torch.tensor(0)\n",
    "\n",
    "    def __init__(self, alpha: float = 1, beta: float = 2) -> None:\n",
    "        self.alpha: float = alpha\n",
    "        self.beta: float = beta\n",
    "    \n",
    "    def forward(self, embs, ids):\n",
    "        assert len(embs) == len(ids)\n",
    "        assert (embs.ndim == 2) and (ids.ndim == 1)\n",
    "\n",
    "        idxs = torch.arange(0, len(embs))\n",
    "        idx_pairs = torch.combinations(idxs, 2)\n",
    "        emb_pairs = embs[idx_pairs]\n",
    "\n",
    "        pair_dist = torch.norm(emb_pairs[:, 0, :] - emb_pairs[:, 1, :], dim=1)\n",
    "\n",
    "        ids_first = ids[idx_pairs[:, 0]]\n",
    "        ids_second = ids[idx_pairs[:, 1]]\n",
    "        neg_pairs_mask = (ids_first != ids_second)\n",
    "\n",
    "        labels = torch.ones_like(pair_dist)\n",
    "        labels[neg_pairs_mask] = -1\n",
    "\n",
    "        n_neg = torch.sum(neg_pairs_mask).item()\n",
    "        n_pos = len(neg_pairs_mask) - n_neg\n",
    "\n",
    "        pos_weight = 1.0 / n_pos\n",
    "        neg_weight = 1.0 / n_neg\n",
    "\n",
    "        weights = torch.full_like(pair_dist, pos_weight)\n",
    "        weights[neg_pairs_mask] = neg_weight\n",
    "        weights /= weights.sum()\n",
    "\n",
    "        loss = torch.sum(\n",
    "            weights * \n",
    "            torch.maximum(\n",
    "                self.alpha + labels * (pair_dist - self.beta), self._ZERO\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 1, 3]),\n",
       " tensor([[ 1.,  1.,  1.],\n",
       "         [10., 10., 10.],\n",
       "         [ 1.,  1.,  1.],\n",
       "         [ 4.,  4.,  4.]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = torch.tensor([1, 2, 1, 3])\n",
    "embs = torch.tensor([[1, 1, 1], [10, 10, 10], [1, 1, 1], [4, 4, 4]]).float()\n",
    "ids, embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 1],\n",
       "         [0, 2],\n",
       "         [0, 3],\n",
       "         [1, 2],\n",
       "         [1, 3],\n",
       "         [2, 3]]),\n",
       " torch.Size([6, 2]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert len(ids) == len(embs)\n",
    "\n",
    "idxs = torch.arange(0, len(embs))\n",
    "idx_pairs = torch.combinations(idxs, 2)\n",
    "idx_pairs, idx_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([15.5885,  0.0000,  5.1962, 15.5885, 10.3923,  5.1962]),\n",
       " torch.Size([6]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_pairs = embs[idx_pairs]\n",
    "pair_dist = torch.norm(emb_pairs[:, 0, :] - emb_pairs[:, 1, :], dim=1)\n",
    "pair_dist, pair_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_first = ids[idx_pairs[:, 0]]\n",
    "ids_second = ids[idx_pairs[:, 1]]\n",
    "neg_pairs_mask = ids_first != ids_second\n",
    "labels = torch.ones_like(pair_dist)\n",
    "labels[neg_pairs_mask] = -1\n",
    "torch.sum(neg_pairs_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = 1\n",
    "beta = 2\n",
    "\n",
    "margin_loss = torch.mean(torch.maximum(alpha + labels * (pair_dist - beta), torch.tensor(0)))\n",
    "margin_loss"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f91a5d6e4747d83f2ca8abaaaf7aacd52eac54e528eee770e3eb228d51a3694d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit (system)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
