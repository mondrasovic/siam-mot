{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import itertools\n",
    "import pathlib\n",
    "from typing import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from matplotlib import rc\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "font = {'family': 'Times New Roman', 'weight': 'bold', 'size': 12}\n",
    "rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "def create_response_heatmaps(response_maps, reduction='mean'):\n",
    "    if reduction == 'mean':\n",
    "        reduce_func = np.mean\n",
    "    elif reduction == 'max':\n",
    "        reduce_func = np.max\n",
    "    else:\n",
    "        raise ValueError(f\"unsupported reduction {reduction}\")\n",
    "\n",
    "    if response_maps.ndim == 3:\n",
    "        response_maps = np.expand_dims(response_maps, axis=0)\n",
    "\n",
    "    response_maps_reduced = reduce_func(response_maps, axis=1, keepdims=True)\n",
    "    response_maps_reduced = np.transpose(response_maps_reduced, (0, 2, 3, 1))\n",
    "\n",
    "    min_val = np.min(response_maps_reduced)\n",
    "    max_val = np.max(response_maps_reduced)\n",
    "\n",
    "    response_maps_norm = (\n",
    "        ((response_maps_reduced - min_val) / (max_val - min_val)) * 255\n",
    "    ).round().astype(np.uint8)\n",
    "    response_heatmaps = [\n",
    "        cv.applyColorMap(r, cv.COLORMAP_JET) for r in response_maps_norm\n",
    "    ]\n",
    "\n",
    "    return response_heatmaps\n",
    "\n",
    "def image_show(image):\n",
    "    plt.imshow(image[:,:,::-1])\n",
    "\n",
    "image = cv.imread('search.jpg')\n",
    "image_show(image)"
=======
    "import json\n",
    "\n",
    "def make_crowdhuman_iter(box_type='fbox'):\n",
    "    def _iter_crowdhuman_annos(anno_file_path):\n",
    "        with open(anno_file_path) as anno_file:\n",
    "            for anno_entry in map(json.loads, anno_file.readlines()):\n",
    "                image_id = anno_entry['ID']\n",
    "                gt_boxes = anno_entry['gtboxes']\n",
    "\n",
    "                for box_entry in gt_boxes[box_type]:\n",
    "                    yield image_id, box_entry\n",
    "    \n",
    "    return _iter_crowdhuman_annos\n",
    "\n"
>>>>>>> 9a85439b52e67778c9be653769f63a05249d10dc
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maskrcnn_benchmark.structures.bounding_box import BoxList\n",
    "\n",
    "def draw_heatmaps_on_image(image: np.ndarray, heatmaps: np.ndarray, boxlist: BoxList, alpha: float = 0.4):\n",
    "    assert 0 < alpha < 1, \"alpha must be in (0, 1) interval\"\n",
    "\n",
    "    if len(heatmaps) != len(boxlist):\n",
    "        raise ValueError(\"the number of heatmaps and boxes must be equal\")\n",
    "    \n",
    "    boxlist.clip_to_image()\n",
    "    boxlist = boxlist.convert('xyxy')\n",
    "    boxes = boxlist.bbox.numpy().round().astype(np.int)\n",
    "    heatmap_image = np.zeros_like(image)\n",
    "\n",
    "    for heatmap, (x1, y1, x2, y2) in zip(heatmaps, boxes):\n",
    "        heatmap_width = x2 - x1\n",
    "        heatmap_height = y2 - y1\n",
    "\n",
    "        heatmap_resized = cv.resize(heatmap, (heatmap_width, heatmap_height), interpolation=cv.INTER_LANCZOS4)\n",
    "        heatmap_image[y1:y2, x1:x2] = heatmap_resized\n",
    "\n",
    "    image_blend = cv.addWeighted(image, alpha, heatmap_image, 1 - alpha, 0)\n",
    "\n",
    "    return image_blend\n",
    "\n",
    "response_maps = np.random.randn(2, 128, 16, 16)\n",
    "response_heatmaps = create_response_heatmaps(response_maps)\n",
    "box = torch.as_tensor([[-20, 20, 300, 300], [450, 50, 100, 450]])\n",
    "image_height, image_width, _ = image.shape\n",
    "boxlist = BoxList(box, (image_width, image_height), mode='xywh')\n",
    "image_heatmap_blend = draw_heatmaps_on_image(image, response_heatmaps, boxlist)\n",
    "image_show(image_heatmap_blend)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f91a5d6e4747d83f2ca8abaaaf7aacd52eac54e528eee770e3eb228d51a3694d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit (system)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
